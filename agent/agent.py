# agent/agent.py

from openai import OpenAI
from config import API_KEY
from tools.rpc_registry import METHOD_REGISTRY, METHOD_DOCS


class Agent:
    def __init__(
        self,
        api_key: str = API_KEY,
        base_url: str = "https://api.deepseek.com/v1",
        model: str = "deepseek-chat",
    ):
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model = model
        self.system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼éµå®ˆ JSON-RPC 2.0 åè®®çš„æ™ºèƒ½åŠ©æ‰‹ã€‚

æ ¹æ®ç”¨æˆ·çš„ä¸­æ–‡æŒ‡ä»¤ï¼Œç”Ÿæˆç¬¦åˆ JSON-RPC 2.0 è§„èŒƒçš„çº¯ JSON å“åº”ã€‚

ä½ éœ€è¦è¾“å‡ºä»¥ä¸‹ä¸‰ç§ç±»å‹ä¹‹ä¸€ï¼š

1. **è°ƒç”¨è¯·æ±‚ï¼ˆRequestï¼‰**

æ ¼å¼å¦‚ä¸‹ï¼š

{
  "explanation": "xxx", // ç»™ç”¨æˆ·çœ‹çš„è¯´æ˜
  "jsonrpc": {
    "jsonrpc": "2.0",
    "method": "æ–¹æ³•å",
    "params": {
      // æ–¹æ³•æ‰€éœ€çš„å‚æ•°
    },
    "id": å”¯ä¸€æ•´æ•°ID
  }
}
è¿™é‡Œçš„ id å­—æ®µå¿…é¡»æ˜¯æ•´æ•°ä¸”å”¯ä¸€ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªéœ€è¦ç­‰å¾…å“åº”çš„è¯·æ±‚ã€‚
---
2. **é€šçŸ¥ï¼ˆNotificationï¼‰**
æ ¼å¼å¦‚ä¸‹ï¼š
{
  "explanation": "xxx", // ç»™ç”¨æˆ·çœ‹çš„è¯´æ˜
  "jsonrpc": {
    "jsonrpc": "2.0",
    "method": "æ–¹æ³•å",
    "params": {
      // æ–¹æ³•æ‰€éœ€å‚æ•°
    }
    // è¿™é‡Œä¸å¸¦ id å­—æ®µï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªä¸éœ€è¦å“åº”çš„é€šçŸ¥ã€‚
  }
}
---
3. **å“åº”ï¼ˆResponseï¼‰**
æ ¼å¼å¦‚ä¸‹ï¼š
{
  "explanation": "xxx", // ç»™ç”¨æˆ·çœ‹çš„è¯´æ˜
  "jsonrpc": {
    "jsonrpc": "2.0",
    "result": {
      "content": "è¿™é‡Œæ˜¯ä½ è¦è¿”å›ç»™ç”¨æˆ·çš„å…·ä½“å†…å®¹",
      "done": true
      // ä½ ä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šå­—æ®µï¼Œä½†å¿…é¡»åŒ…å« content å’Œ doneã€‚
    },
    "id": è¯·æ±‚ä¸­çš„æ•´æ•°IDï¼Œå¿…é¡»ä¸è¯·æ±‚ä¸­çš„ id ä¿æŒä¸€è‡´
  }
}
---
**ä¸¥æ ¼è¦æ±‚**ï¼š

- åªè¾“å‡ºçº¯ JSONï¼Œç¦æ­¢ä½¿ç”¨ markdown æˆ–å¤šä½™çš„è‡ªç„¶è¯­è¨€è§£é‡Šã€‚
- JSON æ ¼å¼å¿…é¡»æ­£ç¡®ï¼Œå­—æ®µå¿…é¡»å®Œæ•´ã€‚
- æ ¹æ®ç”¨æˆ·æŒ‡ä»¤è‡ªåŠ¨åˆ¤æ–­æ˜¯å‘é€è¯·æ±‚ã€é€šçŸ¥è¿˜æ˜¯å“åº”ã€‚
- æ‰€æœ‰è°ƒç”¨è¯·æ±‚å’Œå“åº”å¿…é¡»æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªå”¯ä¸€æ•´æ•°å‹ id å­—æ®µã€‚
- é€šçŸ¥è¯·æ±‚ä¸åº”åŒ…å« id å­—æ®µã€‚
"""
        self._available_methods = list(METHOD_REGISTRY.keys())
        self.method_docs = METHOD_DOCS  # å‚æ•°è¯´æ˜å­—å…¸
    @property
    def available_methods(self):
        # åŠ¨æ€è¿”å›å½“å‰æ‰€æœ‰æ³¨å†Œçš„JSON-RPCæ–¹æ³•ååˆ—è¡¨
        return list(METHOD_REGISTRY.keys())
    @available_methods.setter
    def available_methods(self, methods):
        self._available_methods = methods
    def ask(self, history_messages: list[dict], known_methods=None, extra_prompt=None) -> str:
        print(f"agent ask= history_messages: {history_messages} known_methods: {known_methods} extra_prompt:")
        system_prompt = self.system_prompt
        if known_methods:
            system_prompt += "\n\nè¯·ä»…ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•åä¹‹ä¸€è°ƒç”¨ JSON-RPC æ¥å£ï¼š"
            system_prompt += ", ".join(known_methods)

            # é™„åŠ å‚æ•°è¯´æ˜ï¼Œç»™æ¨¡å‹æ›´æ¸…æ™°æŒ‡å¼•
            params_info = []
            for method in known_methods:
                if method in self.method_docs:
                    params_desc = self.method_docs[method]
                    params_str = ", ".join(f"{k}: {v}" for k, v in params_desc.items())
                    params_info.append(f"{method}({params_str})")
                else:
                    params_info.append(method)
            if params_info:
                system_prompt += "\n\næ–¹æ³•å’Œå‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š\n" + "\n".join(params_info)

        if extra_prompt:
            system_prompt += "\n\n" + extra_prompt

        messages = [{"role": "system", "content": system_prompt}] + history_messages

        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0.2,
        )
        return response.choices[0].message.content.strip()
    
    def ask_stream(self, history_messages: list[dict], known_methods=None, extra_prompt=None, check_cancel=lambda: False) -> str:
      system_prompt = self.system_prompt
      if known_methods:
          system_prompt += "\n\nè¯·ä»…ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•åä¹‹ä¸€è°ƒç”¨ JSON-RPC æ¥å£ï¼š"
          system_prompt += ", ".join(known_methods)

          # é™„åŠ å‚æ•°è¯´æ˜
          params_info = []
          for method in known_methods:
              if method in self.method_docs:
                  params_desc = self.method_docs[method]
                  params_str = ", ".join(f"{k}: {v}" for k, v in params_desc.items())
                  params_info.append(f"{method}({params_str})")
              else:
                  params_info.append(method)
          if params_info:
              system_prompt += "\n\næ–¹æ³•å’Œå‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š\n" + "\n".join(params_info)

      if extra_prompt:
          system_prompt += "\n\n" + extra_prompt

      messages = [{"role": "system", "content": system_prompt}] + history_messages

      collected_text = ""
      try:
          stream = self.client.chat.completions.create(
              model=self.model,
              messages=messages,
              temperature=0.2,
              stream=True  # å¼€å¯æµå¼
          )

          for chunk in stream:
              if check_cancel():
                  print("ğŸ›‘ ä¸­æ–­è¯·æ±‚ï¼šç”¨æˆ·å–æ¶ˆ")
                  return "ğŸ›‘ å·²å–æ¶ˆå½“å‰ä»»åŠ¡"

              delta = chunk.choices[0].delta
              if hasattr(delta, "content") and delta.content:
                  collected_text += delta.content

          return collected_text.strip()

      except Exception as e:
          return f"âŒ OpenAI è¯·æ±‚å¤±è´¥ï¼š{str(e)}"
